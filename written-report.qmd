---
title: "Factors Impacting Number of LinkedIn Job Applications per Post View"
author: "JRLK - Jessie Ringness, Rebekah Kim, Laura Cai, Karen Dong"
date: 11/14/2023
format: pdf
execute: 
  warning: false
  message: false
editor: visual
---

```{r load_pkg_data}
#| message: false
#| echo: false
library(tidyverse)
library(tidymodels)
library(knitr)
library(patchwork)
library(janitor)
library(ggplot2)
library(patchwork)
job_postings <-read.csv("data/job_postings.csv")
benefits <-read.csv("data/benefits.csv")
employee <-read.csv("data/employee_counts.csv")
```

```{r manipulating_benefits}
#| echo: false
benefits <- benefits |>
  select(-inferred) |>
  mutate(count = 1) |>
  pivot_wider(names_from = "type", values_from = "count") |>
  clean_names()
```

```{r benefits_manipulation}
#| echo: false
benefits <- replace(benefits, is.na(benefits), 0)
benefits$tot_benefits <- rowSums(benefits == 1)
benefits_total <- benefits[, c('job_id', 'tot_benefits')]
```

```{r joining_jobs_employee}
#| echo: false
jobs_employee <- job_postings |>
  left_join(employee, by = join_by("company_id"))
```

```{r joining_final_set}
#| echo: false
linkedin <- jobs_employee |>
  left_join(benefits_total, by = join_by("job_id"))
linkedin <- linkedin |> distinct(job_id, .keep_all = TRUE)
```

```{r replace}
#| echo: false
linkedin[["remote_allowed"]][is.na(linkedin[["remote_allowed"]])] <- 0
linkedin[["tot_benefits"]][is.na(linkedin[["tot_benefits"]])] <- 0
linkedin$remote_allowed <- as.factor(linkedin$remote_allowed)
```

```{r pay_period_mutations}
#| echo: false
linkedin <- linkedin |>
  mutate(per_applies = applies / views) 
linkedin_subset <- linkedin |>
  drop_na(max_salary) |>
  drop_na(pay_period) |>
  mutate(pay_period = recode(pay_period, YEARLY = 2080, HOURLY = 1, MONTHLY = 160)) |>
  mutate(hourly_max_salary = round((max_salary / pay_period), digits = 2))
linkedin_subset <- linkedin_subset |>
  mutate(if_benefits = factor(ifelse(linkedin_subset$tot_benefits > 0, "listed", "none"),
  levels = c("none", "listed")))
```

```{r orig_hour_mutations}
#| echo: false
linkedin_subset <- linkedin_subset |>
  mutate(original_listed_time = as.POSIXct(original_listed_time/1000, 
                                           origin = "1970-01-01", 
                                           tz = "EST")) |>
  mutate(listed_time = as.POSIXct(listed_time/1000, 
                                  origin = "1970-01-01", 
                                  tz = "EST")) 
linkedin_subset$hour_listed <- sapply(strsplit(as.character(linkedin_subset$original_listed_time), ' '), function(x) {
  time_parts <- unlist(strsplit(x[2], ':'))
  return(as.numeric(time_parts[1]))
})
```

```{r filtering_data}
linkedin_subset <- linkedin_subset |> 
  filter(between(hourly_max_salary, 19.31, 114.04)) |>
  filter(between(follower_count, 328.15, 3326613.00)) |>
  filter(views>5)
```

```{r drop_vars}
#| echo: false
linkedin_subset <- subset(linkedin_subset, select = c(job_id,
                                            formatted_work_type,
                                            hour_listed,
                                            formatted_experience_level,
                                            remote_allowed,
                                            work_type,
                                            employee_count,
                                            follower_count,
                                            per_applies,
                                            hourly_max_salary,
                                            if_benefits))
linkedin_subset <- linkedin_subset |>
  filter(formatted_experience_level != "") |>
  drop_na(c(job_id,
            formatted_work_type,
            hour_listed,
            formatted_experience_level,
            remote_allowed,
            work_type,
            employee_count,
            follower_count,
            per_applies,
            hourly_max_salary,
            if_benefits))
```



## Introduction and data

LinkedIn is a popular platform that connects companies and professionals spanning various levels of experience, and there are thousands of active job postings available on LinkedIn. Moreover, online job search services and platforms are now considered equally important for people to access a wide variety of opportunities compared to in-person job postings. With the sheer amount of postings, applicants may be overwhelmed by the vast amount of postings, and are less likely to come across some postings over others. Our primary research question is - what variables about job postings increase popularity among applicants?

This data set was created by Arsh Koneru-Ansari in July 2023, who used Python to scrape data directly from linkedin.com. The scraper code is published in their [GitHub](https://github.com/ArshKA/LinkedIn-Job-Scraper#jobs).

The data dictionary for the variable definitions can be found in the ReadMe for the data. The variables we will focus on are:

-   **`applies`:** number of applications that have been submitted

-   **`views`:** number of times the job posting has been viewed

-   **`max_salary`:** maximum salary offered in the position 

-   **`remote_allowed`:** whether job permits remote work (1 = yes)

-   **`follower_count`:** number of company followers on LinkedIn

-   **`listed_time`:** time when the job was listed, in UNIX time

-   **`formatted_experience_level`:** job experience level (entry level, associate, mid-senior level, director, executive, internship) 

-   **`type`**: type of benefit provided (Medical insurance, Dental insurance, 401(k), Paid maternity leave, Disability insurance, Vision insurance, Tuition assistance, Pension plan, Child care support, Commuter benefits, Student loan assistance)

Another potential interaction effect is the number of views and experience level. Different positions are more sought after on LinkedIn over others, depending on viewers' backgrounds. The number of applications increases per number of views for a position requiring associate experience increases at a more rapid rate than those for other positions, although all positions have some sort of impact associated with views and applications.

```{r numerical_plots}
#| echo: false
salary_hist <- linkedin_subset |>
  ggplot(aes(x = hourly_max_salary)) + 
  geom_histogram() +
  labs(x = "Hourly Max Salary",
       y = "Jobs",
       title = "Max Salary (Hourly) Distribution")
follower_hist <- linkedin_subset |>
  ggplot(aes(x = follower_count)) + 
  geom_histogram() +
  labs(x = "Follower Count",
       y = "Jobs",
       title = "Follower Count Distribution")
hr_hist <- linkedin_subset |>
  ggplot(aes(x = as.numeric(hour_listed))) + 
  geom_histogram() +
  labs(x = "Hour Listed",
       y = "Jobs",
       title = "Jobs Posted Over Time")

(salary_hist + hr_hist) / (follower_hist)
```
```{r summary statistics}
sal_quantile<-quantile(linkedin_subset$hourly_max_salary, probs = c(0.05, 0.5, 0.95), na.rm =TRUE)
follower_quantile<-quantile(linkedin_subset$follower_count, probs = c(0.05, 0.5, 0.95),na.rm =TRUE) 
views_quantile<-quantile(linkedin_subset$views, probs = c(0.1,0.5, 0.95), na.rm = TRUE)
```


```{r}
linkedin_subset_small <- linkedin_subset[, c(3,8,10)]
summary_stats <- summary(linkedin_subset_small) 
print(summary_stats)

```

*Fig 1.1.* The distribution of hourly maximum salary is right skewed with its median around 50 dollars an hour and an IQR of 33 dollars an hour, demonstrating how the variability it relatively high. The histogram shows the middle 90% of the data to filter out the significant outliers.

*Fig 1.2.* The distribution of the hour listed is left skewed and is concentrated mainly between 2:00 PM and 7:00 PM, with a median around 4:00 PM and an IQR of 4 hours, showing how the variability is relatively high 

*Fig 1.3.* The distribution of follower count is, with a median of around 70 thousand followers. The histogram shows the middle 90% of the data to filter out the significant outliers. The IQR is over 280,000 followers, which means there is high variability. 

```{r }
#| echo: false
experience_plot <- linkedin_subset |>
  ggplot(aes(x = hourly_max_salary, y = per_applies, color = formatted_experience_level)) +
  geom_point() + 
  geom_smooth(method = 'lm',formula = y ~ x, se = F) +
  labs(x = "Hourly Maximum Salary",
       y = "Applications per view",
       color = "Experience Level",
       title = "Applications per view based on 
       experience level and maximum salary") + 
  facet_wrap(~formatted_experience_level)
experience_plot 
```

```{r}
tapply(linkedin_subset$per_applies, linkedin_subset$formatted_experience_level, summary)
```


*Fig 2.* The distribution of applications per view based on experience level and maximum salary is mostly concentrated when the applications per view is less than 0.50 and the hourly maximum salary is less than 200 for each experience level. The mid-senior level has apparent outliers when the hourly maximum salary is greater than 200 and the NA level has outliers when the applications per view is above 0.75. There is also not as much data for some of the experience levels, including internship and executive.

```{r}
#| echo: false
salary_scat <- linkedin_subset |>
  ggplot(aes(x = hourly_max_salary, y = per_applies)) +
  geom_point() +
  labs(x = "Hourly Max Salary")

follow_scat <- linkedin_subset |>
  filter(follower_count > 10000) |>
  ggplot(aes(x = follower_count, y = per_applies)) +
  geom_point() +
  labs(x = "Follower Count")

hr_scat <- linkedin_subset |>
  ggplot(aes(x = hour_listed, y = per_applies)) +
  geom_point() +
  labs(x = "Hour Listed")

(follow_scat + salary_scat) / hr_scat
```

```{r}
#| echo: false
group <- linkedin_subset |>
  group_by(hour_listed) |>
  summarize(mean_per_applies = mean(per_applies))
```

```{r}
#| echo: false
group |>
  ggplot(aes(x = hour_listed, y = mean_per_applies)) +
  geom_col() +
  labs(x = "Hour Listed")
```

*Fig 3.1.* There is a slight linear correlation between follower count of a company and percentage of viewers who apply to the job. Most of the observations are concentrated to have less than 1,000,000 followers, so it would be beneficial to remove outliers that have more followers than that.

*Fig 3.2.* There is a slight positive linear correlation between a job's adjusted hourly maximum salary and percentage of viewers who apply to the job. Most of the observations are concentrated to have less than \$200,000 for adjusted hourly max salary, so it would be beneficial to filter out outliers that are above this threshold. Additionally, it would be beneficial to remove the outlier where 100% of viewers applied to the job (per_applies = 1.0)

*Fig 3.3.* Convert to categorical variable, make a histogram that's colored by morning, afternoon, evening

*Fig 3.4.* This figure could be statistically misleading since the intervals are not consistent, and mean_per_applies is not a helpful response variable for the model. We should convert hour_listed to a categorical variable and create a pie chart instead to show the frequency of each level.

## Methodology
~~
We are provided with data regarding benefits, where it listed types of benefits provided for each company, and data regarding job postings, which lists the posted jobs scraped from LinkedIn on July 23 and 24, 2023. To prepare our data for our model:
We counted the total benefits offered by each company to prepare out “if_benefits” predictor. 
We joined the datasets to use the benefits predictor with other predictors. 
We made the assumption that if there were NAs for “remote_allowed” and “tot_benefits” for jobs/companies that didn’t allow remote and had no listed benefits. Therefore, we imputed them to 0’s. We filtered out the other values that were NA.
We created an “hourly_max_salary” predictor variable to compare the salaries even if they were listed as monthly or annually. 
To use the data relating to the time the job was posted, we converted the time format to EST time and kept only kept the hour.
To remove significant outliers that may affect the model and its precision, we filtered to keep only the middle 90% of data for the “hourly_max_salary” and “follower_count” variables.
In order to generalize our results to jobs with not too few views, we filtered out the jobs that had less than 5 views.
~~

While the bulk of our data was found in the \`job_postings\` data set, we also wanted to include employee count and follower count data in the \`employee\` data set and the type and number of benefits listed on the post found in the \`benefits\` data set. We needed to manipulate the data in 'benefits' to create a useful predictor as the majority of the data was NA, meaning no benefits could be found from the scraped data. To make the data from \`benefits\` a useful predictor, we created a new categorical variable called \`'if_benefits\` where if a benefit (such as paid maternity leave or a 401k plan) was listed on the post, then the post was considered as having benefits \`listed\`, and otherwise was listed as \`none\` listed. We joined all data sets together by \`company_id\`, and saved the data set as \`linkedin\`. 

We also made some assumptions about other variables to normalize predictor variables. The categorical variable \`pay_period\` contained data on when the job would pay its worker the \`max_salary\` or \`min_salary\` amount, with hourly, monthly, and annual payments as the different levels. To normalize the \`max_salary\` amount, we calculated the hourly wage given the maximum pay for hourly, monthly, and yearly pay periods. We assumed 160 hours for the monthly payments (40 hour work week for 4 weeks), and 2080 hours for the annual payments (40 hour work week for 52 weeks). We saved the new data in a variable called \`hourly_max_salary\`. 

We then dropped all \`NA\` values for all predictors we wanted to observe so that we could keep our dataset consistent when testing different models, meaning NA values for \`hourly_max_salary\`, \`per_applies\`, \`follower_count\`, \`formatted_experience_level\`, \`original_listed_time\`, and \`remote_allowed\`. 

Because the number of views an application gets is directly related to the number of applications and the jobs have been listed for varying durations of time, we decided to normalize the number of applications with the views. To do so, we created a new variable \`per_applies\`. We then used \`per_applies\` as our response variable. 

Because \`per_applies\` is a numerical variable, a linear regression model would be most appropriate to predict the number of applications per view. As we addressed in the introduction, a person takes into consider many different factors when applying to a job, so our model takes into consideration multiple predictors, including the hour the job was posted, the number of followers the company has, the job experience level, the maximum salary, ability to work remote, and if benefits are listed. 

We split the \`linkedin\` dataset into training and testing data, with 75% of the data in training and 25% in testing. We then used cross-fold validation with 12 folds on the training data set to find the mean summary statistics (AIC,  BIC, Adjusted R-Squared) for each model and compared the different values to find the best possible model. This process was repeated for models containing each combination of predictor variables. We set a seed of (2) when splitting and folding the data to ensure reproducibility.

```{r split_data}
#| echo: false
set.seed(2)
linkedin_split <- initial_split(linkedin_subset)
linkedin_train <- training(linkedin_split)
linkedin_test <- testing(linkedin_split)
```

```{r cross_val}
#| echo: false
set.seed(2)
folds <- vfold_cv(linkedin_train, v = 12)
linkedin_spec <- linear_reg() |>
  set_engine("lm")
```

```{r recipe_1}
#| echo: false
set.seed(2)
linkedin_recipe1 <- recipe(per_applies ~ job_id + hourly_max_salary + follower_count + remote_allowed + formatted_experience_level + if_benefits + hour_listed, data = linkedin_train) |>
  update_role(job_id, new_role = "ID") |> 
  step_center(hourly_max_salary, follower_count) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())
```

```{r recipe_2}
#| echo: false
set.seed(2)
linkedin_recipe2 <- recipe(per_applies ~ job_id + follower_count + remote_allowed + formatted_experience_level, 
                           data = linkedin_train) |>
  update_role(job_id, new_role = "ID") |> 
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors())
```

```{r workflow_1}
#| echo: false
set.seed(2)
linkedin_wflow1 <- workflow() |>
  add_recipe(linkedin_recipe1) |>
  add_model(linkedin_spec)
```

```{r workflow_2}
#| echo: false
set.seed(2)
linkedin_wflow2 <- workflow() |>
  add_recipe(linkedin_recipe2) |>
  add_model(linkedin_spec)
```

```{r}
set.seed(2)
calc_model_stats <- function(x) {
  glance(extract_fit_parsnip(x)) |>
    select(adj.r.squared, AIC, BIC)
}
```

```{r resampled_fits}
#| echo: false
set.seed(2)
linkedin_fit_rs_full <- linkedin_wflow1 |>
  fit_resamples(resamples = folds, 
                control = control_resamples(extract = calc_model_stats))
linkedin_fit_rs_red <- linkedin_wflow2 |>
  fit_resamples(resamples = folds, 
                control = control_resamples(extract = calc_model_stats))
```

```{r resample_mean_stats}
map_df(linkedin_fit_rs_full$.extracts, ~ .x[[1]][[1]]) |>
  summarise(mean_adj_rsq = mean(adj.r.squared), 
            mean_aic = mean(AIC), 
            mean_bic = mean(BIC))
map_df(linkedin_fit_rs_red$.extracts, ~ .x[[1]][[1]]) |>
  summarise(mean_adj_rsq = mean(adj.r.squared), 
            mean_aic = mean(AIC), 
            mean_bic = mean(BIC))
```


The adjusted R\^2 value for a model including `hourly_max_salary`, `follower_count`, `remote_allowed`, `formatted_experience_level`, `hour_listed`, and `if_benefits` was 0.02455995. We removed variables one by one, but each model resulted in a lower R\^2 value, indicating that a model including all mentioned variables is the best.

```{r red_vs_full_fits}
linkedin_fit_full <- linkedin_wflow1 |>
  fit(data = linkedin_test)

tidy(linkedin_fit_full) |>
  kable(digits = 3)
```

Using a significance level of $\alpha = 0.10$, `follower_count`, `hour_listed`, `remote_allowed`, and if the job requires internship or director level of experience are the only statistically significant variables, with p-values of 0.049, 0.053, 0.020, and 0.012 respectively. A smaller model using `hour_listed`, `follower_count`, `remote_allowed`, and `formatted_experience_level` was made. 

```{r}
library(rms)
linkedin_full_fit <- linear_reg() |>
  set_engine("lm") |>
  fit(per_applies ~ hourly_max_salary + follower_count + remote_allowed + formatted_experience_level + if_benefits + hour_listed, data = linkedin_subset)


vif(linkedin_full_fit$fit)
```
Multicollinearity occurs where there are very high correlations among two or more predictor variables, and we need to check for multicollinearity because it causes a loss in precision in our estimates of the regression coefficients. It is a concern when VIF is greater than 10 for a predictor, which is not the case in our model.

Conditions

We need to check linearity, constant variance, normality, and independence as conditions for inference. 

Linearity
```{r}
linkedin_full_aug <- augment(linkedin_full_fit$fit)
```

```{r}
ggplot(data = linkedin_full_aug, aes(x = .fitted, y = .resid)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Predicted values", y = "Residuals")
```


```{r summarize_test_stats}
#linkedin_test_pred_full <- predict(linkedin_fit_full, linkedin_train) |>
  #bind_cols(linkedin_train)
#map_df(linkedin_fit_full$.extracts, ~ .x[[1]][[1]]) |>
  #summarise(mean_adj_rsq = mean(adj.r.squared), 
            #mean_aic = mean(AIC), 
            #mean_bic = mean(BIC))

#linkedin_test_pred_red <- predict(linkedin_fit_red, linkedin_train) |>
  #bind_cols(linkedin_train)
#rsq(linkedin_test_pred_red, truth = per_applies, estimate = .pred)
```


## Results

```{r}
linkedin_yr_rec <- recipe(per_applies ~ job_id + hourly_max_salary + follower_count + remote_allowed + formatted_experience_level + if_benefits + hour_listed, data = linkedin_subset) |> 
  update_role(job_id, new_role = "ID") |> 
  step_naomit(all_predictors()) |>
  step_dummy(all_nominal_predictors()) |> 
  step_zv(all_predictors())
```

```{r}
#specify the model
linkedin_yr_spec <- linear_reg() |>
  set_engine("lm")

#build model workflow
linkedin_yr_workflow <- workflow() |>
  add_model(linkedin_yr_spec) |>
  add_recipe(linkedin_yr_rec) 

# fit the model 
linkedin_yr_fit <- linkedin_yr_workflow |>
  fit(data = linkedin_subset) 

tidy(linkedin_yr_fit) |>
  kable(digits = 3)
```

```{r}
glance(linkedin_yr_fit)
```

Looking at the how the maximum salary, follower count, whether the job allows remote, the experience level, if there were benefits listed, and the hour at which the job was listed all affected the ratio of applications to views, there is no significant relationship between these variables, since the adjusted R\^2 s 0.0589, which is very low. This means that about 6% of the variation in the percent of viewers that applied is a result of the variation in the predictor variables we are studying, indicating no relationship.We tried different combinations of variables to see if there was any relationship between the variables with percent of viewers that applied.

## Discussion + Conclusion

While we had expected the percent of viewers that applied for each job to increase as the maximum salary and number of followers increase, our model and EDA have demonstrated how there is no relationship between these variables, along with having a remote option, the job experience level, the hour at which it was posted, and if the benefits were posted, and our response variable of the percent of viewers who applied.

Some of the limitations with our analysis may include assumption errors with the number of hours the job would work for the jobs listed as yearly and monthly, the filtering of outliers and deciding the thresholds for outliers, model complexity where we are fitting many predictor variables, and the lack of data considering how long the jobs were listed.

Some ways our analysis could be improved would be filtering out the outliers better, deciding the thresholds for views, follower count, salaries, etc, that would avoid skewing the data.

Potential issues relating to the data would include the time scraped from LinkedIn, since many of the original listed times and the listed times (the time it was scraped) is exactly the same, which is not meaningful in determining the number of applications over a certain amount of time.
